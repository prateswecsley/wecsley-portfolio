<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <title>NLP Topic Modeling System - Methodology | Wecsley Prates</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6; color: #333; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 2rem 0; }
        .container { max-width: 1200px; margin: 0 auto; padding: 0 2rem; }
        .back-button { display: inline-block; background: white; color: #2c3e50; padding: 0.8rem 1.5rem; text-decoration: none; border-radius: 5px; margin-bottom: 2rem; font-weight: 600; transition: all 0.3s; box-shadow: 0 4px 15px rgba(0,0,0,0.1); }
        .back-button:hover { transform: translateY(-2px); box-shadow: 0 6px 20px rgba(0,0,0,0.15); }
        .project-header { background: linear-gradient(135deg, #16a085 0%, #138d75 100%); color: white; padding: 3rem 2rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }
        .project-header h1 { font-size: 2.5rem; margin-bottom: 0.5rem; }
        .project-header .company { font-size: 1.2rem; opacity: 0.9; margin-bottom: 1rem; }
        .project-header .date { font-size: 1rem; opacity: 0.8; }
        .content-section { background: white; padding: 2.5rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 5px 20px rgba(0,0,0,0.1); }
        .content-section h2 { color: #2c3e50; font-size: 1.8rem; margin-bottom: 1.5rem; padding-bottom: 0.5rem; border-bottom: 3px solid #16a085; }
        .content-section h3 { color: #34495e; font-size: 1.4rem; margin-top: 1.5rem; margin-bottom: 1rem; }
        .content-section h4 { color: #7f8c8d; font-size: 1.1rem; margin-top: 1rem; margin-bottom: 0.5rem; }
        .content-section p { margin-bottom: 1rem; text-align: justify; }
        .content-section ul, .content-section ol { margin-left: 2rem; margin-bottom: 1rem; }
        .content-section li { margin-bottom: 0.5rem; }
        .highlight-box { background: #f8f9fa; border-left: 4px solid #16a085; padding: 1.5rem; margin: 1.5rem 0; border-radius: 5px; }
        .tech-stack { display: flex; flex-wrap: wrap; gap: 0.8rem; margin: 1rem 0; }
        .tech-badge { background: linear-gradient(135deg, #16a085, #138d75); color: white; padding: 0.5rem 1rem; border-radius: 20px; font-size: 0.9rem; font-weight: 600; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        .metrics-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1.5rem; margin: 2rem 0; }
        .metric-card { background: linear-gradient(135deg, #3498db, #2980b9); color: white; padding: 1.5rem; border-radius: 10px; text-align: center; box-shadow: 0 5px 15px rgba(0,0,0,0.1); }
        .metric-number { font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem; }
        .metric-label { font-size: 1rem; opacity: 0.9; }
        .workflow-diagram { background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); padding: 2rem; border-radius: 10px; margin: 1.5rem 0; border: 2px solid #16a085; }
        .workflow-diagram h4 { color: #16a085; margin-bottom: 1.5rem; font-size: 1.3rem; text-align: center; }
        .flow-step { display: flex; align-items: flex-start; margin: 1.5rem 0; padding: 1.5rem; background: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); border-left: 4px solid #16a085; }
        .flow-step .step-number { background: #16a085; color: white; width: 45px; height: 45px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; font-size: 1.2rem; margin-right: 1.5rem; flex-shrink: 0; }
        .flow-step strong { color: #2c3e50; display: block; margin-bottom: 0.5rem; font-size: 1.1rem; }
        .flow-step em { color: #7f8c8d; font-style: normal; display: block; margin: 0.3rem 0; }
        .flow-step em:before { content: '‚Üí '; color: #16a085; font-weight: bold; }
        .pipeline-visual { background: white; padding: 2rem; border-radius: 10px; margin: 2rem 0; border: 2px solid #3498db; }
        .pipeline-visual h4 { color: #3498db; text-align: center; margin-bottom: 1.5rem; }
        .pipeline-step { background: linear-gradient(135deg, #3498db, #2980b9); color: white; padding: 1rem 1.5rem; border-radius: 8px; margin: 1rem 0; position: relative; }
        .pipeline-step:not(:last-child):after { content: '‚ñº'; display: block; text-align: center; color: #3498db; font-size: 2rem; margin: 0.5rem 0; }
        .methodology-box { background: #fff3cd; border-left: 4px solid #f39c12; padding: 1.5rem; margin: 1.5rem 0; border-radius: 5px; }
        .methodology-box h4 { color: #f39c12; margin-bottom: 0.8rem; }
        .decision-box { background: #d1ecf1; border-left: 4px solid #17a2b8; padding: 1.5rem; margin: 1.5rem 0; border-radius: 5px; }
        .decision-box h4 { color: #17a2b8; margin-bottom: 0.8rem; }
        .impact-section { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 2.5rem; border-radius: 15px; margin-top: 2rem; }
        .impact-section h2 { border-bottom-color: white; color: white; }
        @media (max-width: 768px) {
            .project-header h1 { font-size: 2rem; }
            .content-section { padding: 1.5rem; }
            .metrics-grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="index.html" class="back-button">‚Üê Back to Portfolio</a>

        <div class="project-header">
            <h1>üìö NLP Topic Modeling System</h1>
            <div class="company">US Foods</div>
            <div class="date">March 2021 - September 2021 | Rosemont, IL</div>
        </div>

        <div class="content-section">
            <h2>Project Overview</h2>
            <p>
                Built an automated topic modeling system using Latent Dirichlet Allocation (LDA) to analyze 2 million+ customer survey responses at US Foods. The system automatically discovered 15 distinct themes (e.g., "delivery timeliness", "product freshness", "driver professionalism") without manual labeling, enabling the customer experience team to prioritize improvements and reducing manual review time from 8 weeks to 2 days.
            </p>
            <div class="highlight-box">
                <strong>The Challenge:</strong> US Foods collected 2M+ free-text survey responses annually ("How was your delivery experience?"), but had no systematic way to analyze them. Customer experience team manually read 1-2% of responses (random sample), missing 98% of feedback. Leadership had no quantitative view of what customers actually cared about‚Äîjust anecdotes and gut feel.
            </div>
        </div>

        <div class="content-section">
            <h2>üìä Methodology & Workflow</h2>
            
            <div class="pipeline-visual">
                <h4>End-to-End NLP Pipeline</h4>
                <div class="pipeline-step">
                    <strong>Phase 1: Data Collection & Preprocessing</strong><br>
                    Survey responses ‚Üí Text cleaning ‚Üí Tokenization ‚Üí Stop word removal ‚Üí Lemmatization
                </div>
                <div class="pipeline-step">
                    <strong>Phase 2: Exploratory Text Analysis</strong><br>
                    Word frequency ‚Üí N-gram analysis ‚Üí Document length distribution ‚Üí Domain vocabulary discovery
                </div>
                <div class="pipeline-step">
                    <strong>Phase 3: Topic Modeling (LDA)</strong><br>
                    Model selection ‚Üí Hyperparameter tuning ‚Üí Topic coherence optimization ‚Üí Label interpretation
                </div>
                <div class="pipeline-step">
                    <strong>Phase 4: Validation & Refinement</strong><br>
                    Human validation ‚Üí Topic stability testing ‚Üí Optimal topic count selection
                </div>
                <div class="pipeline-step">
                    <strong>Phase 5: Deployment & Visualization</strong><br>
                    R Shiny dashboard ‚Üí Automated monthly reports ‚Üí Trend analysis over time
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 1: Text Preprocessing Strategy</h2>
            
            <div class="methodology-box">
                <h4>üí° The Preprocessing Dilemma: How Much Cleaning?</h4>
                <p><strong>Problem:</strong> Raw survey text is messy ("GREAT delivery!!! Driver was 5 stars :)")</p>
                <p><strong>Trade-off:</strong> Over-clean (lose meaning) vs. Under-clean (model sees noise)</p>
                <p><strong>Decision Framework:</strong></p>
                <ul>
                    <li><strong>Keep:</strong> Domain-specific terms ("temp check", "invoice"), negations ("not fresh")</li>
                    <li><strong>Remove:</strong> Generic filler ("the", "and"), HTML artifacts, extreme outliers</li>
                    <li><strong>Normalize:</strong> Spelling variants ("delivered" = "deliver"), case-insensitive</li>
                </ul>
            </div>

            <div class="workflow-diagram">
                <h4>üîÑ Text Cleaning Workflow</h4>
                
                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Data Extraction & Initial Filtering</strong><br>
                        <em>Source: Qualtrics survey platform (2019-2021, 2.1M responses)</em>
                        <em>Question: "What could we improve about your delivery experience?"</em>
                        <em>Initial Filter: Removed responses <10 characters (e.g., "N/A", ".", "good") - Not informative</em>
                        <em>Removed: Responses >500 words (0.3% - outliers, likely spam or pasted content)</em>
                        <em>Final Dataset: 1.87M meaningful responses (average 42 words each)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Text Normalization</strong><br>
                        <em>Lowercase Conversion: "DRIVER WAS LATE" ‚Üí "driver was late"</em>
                        <em>Punctuation Removal: "Great!!!" ‚Üí "Great" (preserving sentence structure)</em>
                        <em>Number Handling: Replaced specific numbers with token ‚Üí "waited 45 minutes" ‚Üí "waited NUM minutes"</em>
                        <em>Rationale: "45 minutes" and "60 minutes" should map to same concept (long wait time)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Tokenization & Stop Word Removal</strong><br>
                        <em>Tokenization: Split sentences into words ‚Üí "driver was late" ‚Üí ["driver", "was", "late"]</em>
                        <em>Stop Words: Removed generic terms ("the", "and", "is", "was") using NLTK list + custom additions</em>
                        <em>Custom Stop Words: Added domain-agnostic words ("thing", "stuff", "ok", "fine")</em>
                        <em>Why Remove: Stop words add noise without meaning (appear in all topics)</em>
                        <em>Result: 40% token reduction while preserving semantic content</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>Lemmatization (NOT Stemming)</strong><br>
                        <em>Goal: Reduce words to base form ‚Üí "delivered", "delivering", "delivers" ‚Üí "deliver"</em>
                        <em>Method: Lemmatization (context-aware) vs. Stemming (rule-based truncation)</em>
                        <em>Why Lemmatization: Preserves readability ("better" stays "better", not "bett")</em>
                        <em>Tool: spaCy en_core_web_sm model (part-of-speech aware)</em>
                        <em>Example: "products were damaged" ‚Üí "product be damage" (grammatical but informative)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">5</div>
                    <div>
                        <strong>Bigram/Trigram Detection</strong><br>
                        <em>Problem: "customer service" is single concept, but appears as ["customer", "service"]</em>
                        <em>Solution: Detect frequent multi-word phrases using Gensim Phrases</em>
                        <em>Discovered Bigrams: "customer_service", "delivery_window", "product_quality", "invoice_error"</em>
                        <em>Threshold: Phrases appearing 100+ times with high pointwise mutual information</em>
                        <em>Impact: Improved topic coherence by treating phrases as single tokens</em>
                    </div>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 2: Exploratory Text Analysis</h2>

            <div class="decision-box">
                <h4>üîç Understanding the Data Before Modeling</h4>
                <p><strong>Philosophy:</strong> "You can't model what you don't understand"</p>
                <p><strong>Goal:</strong> Discover data characteristics that inform modeling decisions</p>
                <p><strong>Questions to Answer:</strong></p>
                <ul>
                    <li>What words appear most frequently? (Indicates dominant themes)</li>
                    <li>How long are documents? (Affects topic model performance)</li>
                    <li>Are there domain-specific vocabularies? (Need custom preprocessing)</li>
                    <li>How many unique topics might exist? (Initial estimate for model)</li>
                </ul>
            </div>

            <div class="workflow-diagram">
                <h4>üìà Exploratory Findings</h4>

                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Word Frequency Analysis</strong><br>
                        <em>Top Terms: "delivery" (342K mentions), "driver" (298K), "time" (245K), "product" (218K)</em>
                        <em>Insight: Delivery experience dominates feedback (not product quality)</em>
                        <em>Surprise: "invoice" mentioned 87K times (billing issues more common than expected)</em>
                        <em>Action: Flagged to finance team as separate workstream</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Sentiment Distribution</strong><br>
                        <em>Method: VADER sentiment analysis (rule-based, fast)</em>
                        <em>Finding: 62% positive, 28% neutral, 10% negative</em>
                        <em>Interpretation: Most customers satisfied, but negatives worth investigating</em>
                        <em>Decision: Run separate LDA models on positive vs. negative responses</em>
                        <em>Rationale: Positive feedback discusses different topics than complaints</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Document Length Distribution</strong><br>
                        <em>Median: 35 words, Mean: 42 words, Range: 10-500 words</em>
                        <em>Finding: 15% of responses are very short (10-15 words) - "Driver was great, on time"</em>
                        <em>Concern: LDA performs worse on short documents (less context)</em>
                        <em>Solution: Set minimum document length to 20 words (excluded 8% of responses)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>N-Gram Insights</strong><br>
                        <em>Top Bigrams: "on_time" (89K), "customer_service" (76K), "delivery_window" (54K)</em>
                        <em>Top Trigrams: "arrived_on_time", "damage_product_quality", "friendly_professional_driver"</em>
                        <em>Insight: Customers mention specific, actionable issues (not vague complaints)</em>
                        <em>Application: Used these as seed words to validate topic labels later</em>
                    </div>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 3: LDA Topic Modeling</h2>

            <div class="decision-box">
                <h4>üß† Why LDA Over Other Topic Modeling Methods?</h4>
                <p><strong>Alternative Methods Considered:</strong></p>
                <ul>
                    <li><strong>K-Means Clustering:</strong> Requires fixed document vectors (TF-IDF), assumes spherical clusters (not realistic for text)</li>
                    <li><strong>NMF (Non-negative Matrix Factorization):</strong> Similar to LDA but less interpretable (lacks probabilistic interpretation)</li>
                    <li><strong>BERTopic (Transformer-based):</strong> State-of-art but computationally expensive (2M documents would take weeks)</li>
                    <li><strong>Rule-Based Keywords:</strong> Manual effort, misses emergent themes, requires constant updating</li>
                </ul>
                <p><strong>Why LDA Won:</strong></p>
                <ul>
                    <li>‚úì Probabilistic: Each document is a mixture of topics (realistic‚Äîcustomer might discuss both delivery AND product)</li>
                    <li>‚úì Unsupervised: Discovers topics automatically without labeled training data</li>
                    <li>‚úì Interpretable: Topics = word distributions (human-readable)</li>
                    <li>‚úì Scalable: Handles 2M documents in hours (not weeks)</li>
                    <li>‚úì Proven: Standard in industry for large-scale text analysis</li>
                </ul>
            </div>

            <div class="workflow-diagram">
                <h4>‚öôÔ∏è LDA Model Training Process</h4>

                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Dictionary & Corpus Creation</strong><br>
                        <em>Dictionary: Map each unique word to integer ID (vocabulary size: 8,500 terms after filtering)</em>
                        <em>Filtering: Removed words appearing in <10 documents (too rare) or >70% of documents (too common)</em>
                        <em>Corpus: Bag-of-words representation ‚Üí Each document = list of (word_id, frequency) tuples</em>
                        <em>Example: "driver was late" ‚Üí [(234, 1), (891, 1)] (after stop word removal)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Optimal Number of Topics (k)</strong><br>
                        <em>Challenge: LDA requires specifying k (number of topics) upfront</em>
                        <em>Method: Trained models with k = 5, 10, 15, 20, 25, 30 topics</em>
                        <em>Evaluation Metric: Coherence Score (measures topic interpretability)</em>
                        <em>Results: k=15 had highest coherence (0.52), k=20 and k=25 similar (0.49)</em>
                        <em>Business Validation: Showed 15-topic model to CX team ‚Üí Confirmed topics were distinct and actionable</em>
                        <em>Decision: k=15 (sweet spot between granularity and interpretability)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Hyperparameter Tuning</strong><br>
                        <em>Alpha (document-topic density): Controls how mixed topics are in each document</em>
                        <em>  ‚Ä¢ Low alpha (0.01): Documents focus on 1-2 topics (sparse)</em>
                        <em>  ‚Ä¢ High alpha (0.5): Documents spread across many topics (uniform)</em>
                        <em>  ‚Ä¢ Optimal: 0.1 (most responses focus on 2-3 themes)</em>
                        <em>Beta (topic-word density): Controls word distribution within topics</em>
                        <em>  ‚Ä¢ Optimal: 0.01 (topics are specific, not generic word clouds)</em>
                        <em>Iterations: 500 passes (convergence confirmed via perplexity plateau)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>Topic Interpretation & Labeling</strong><br>
                        <em>LDA Output: 15 topics, each = distribution over 8,500 words</em>
                        <em>Top Words Extraction: For each topic, extracted 20 highest-probability words</em>
                        <em>Example Topic 3: ["late", "delivery", "window", "schedule", "arrive", "time", "wait", "hour"]</em>
                        <em>Human Labeling: CX team reviewed top words + sample documents ‚Üí Labeled "Delivery Timeliness"</em>
                        <em>Validation: Read 50 random documents per topic to confirm label accuracy (92% agreement)</em>
                    </div>
                </div>
            </div>

            <div class="methodology-box">
                <h4>üìã Discovered Topic Themes (15 Total)</h4>
                <p><strong>Top 5 Topics by Volume:</strong></p>
                <ol>
                    <li><strong>Delivery Timeliness (22% of responses):</strong> "late", "on time", "delivery window", "schedule"</li>
                    <li><strong>Driver Professionalism (18%):</strong> "driver", "friendly", "courteous", "professional", "helpful"</li>
                    <li><strong>Product Freshness (15%):</strong> "fresh", "quality", "spoiled", "temperature", "cold chain"</li>
                    <li><strong>Order Accuracy (12%):</strong> "wrong item", "missing", "substitute", "out of stock"</li>
                    <li><strong>Invoice & Billing (10%):</strong> "invoice", "charge", "price", "billing error", "overcharge"</li>
                </ol>
                <p><strong>Other Topics:</strong> Packaging damage, delivery location issues, communication/notifications, product variety, portion sizes, customer service responsiveness, driver safety, COVID-19 protocols, sustainability/packaging waste, payment options</p>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 4: Model Validation & Refinement</h2>

            <div class="workflow-diagram">
                <h4>‚úÖ Validation Strategy</h4>

                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Topic Coherence Testing</strong><br>
                        <em>Metric: C_v coherence score (measures semantic similarity of top topic words)</em>
                        <em>Baseline (Random Topics): 0.18 coherence</em>
                        <em>Our Model: 0.52 coherence (nearly 3x better than random)</em>
                        <em>Benchmark: Published LDA studies report 0.45-0.60 (we're in competitive range)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Human Agreement Study</strong><br>
                        <em>Test: 3 CX analysts independently labeled 100 random responses</em>
                        <em>Question: "Which topic best describes this response?"</em>
                        <em>Inter-rater Agreement: Fleiss' Kappa = 0.71 ("substantial agreement")</em>
                        <em>Model Agreement: Compared model's top topic to human consensus ‚Üí 84% match</em>
                        <em>Interpretation: Model captures human intuition with 84% accuracy</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Topic Stability Over Time</strong><br>
                        <em>Test: Train separate LDA models on Q1, Q2, Q3, Q4 2020 data</em>
                        <em>Question: Do same topics emerge across time periods?</em>
                        <em>Result: 13 of 15 topics consistent across all quarters (87% stability)</em>
                        <em>New Topics: "COVID-19 protocols" emerged in Q2 2020, "contactless delivery" in Q3</em>
                        <em>Conclusion: Topics are stable (not artifacts of specific time period)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>Business Validation</strong><br>
                        <em>Presented findings to VP of Customer Experience</em>
                        <em>Feedback: "These topics align perfectly with known operational challenges"</em>
                        <em>Surprise Finding: Invoice/Billing was #5 topic (previously underestimated)</em>
                        <em>Action: Finance team launched invoice accuracy improvement initiative</em>
                        <em>Outcome: Model credibility established, approved for production deployment</em>
                    </div>
                </div>
            </div>

            <div class="decision-box">
                <h4>üîÑ Iterative Refinement Process</h4>
                <p><strong>Initial Model Issues:</strong></p>
                <ul>
                    <li>Topic 8 was incoherent word salad (mixed themes)</li>
                    <li>Topics 4 and 11 were nearly identical (redundant)</li>
                    <li>Topic 14 dominated by single high-frequency word ("good")</li>
                </ul>
                <p><strong>Refinements Applied:</strong></p>
                <ol>
                    <li>Added "good", "great", "nice" to custom stop word list (too generic)</li>
                    <li>Increased beta parameter to 0.015 (forced more specific word distributions)</li>
                    <li>Reduced k from 20 to 15 (eliminated redundant topics)</li>
                    <li>Re-ran model ‚Üí Coherence improved from 0.47 to 0.52</li>
                </ol>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 5: Deployment & Business Integration</h2>

            <div class="pipeline-visual">
                <h4>üöÄ Production System Architecture</h4>
                <div class="pipeline-step">
                    <strong>Monthly Data Refresh</strong><br>
                    New survey responses exported from Qualtrics ‚Üí Automated preprocessing pipeline
                </div>
                <div class="pipeline-step">
                    <strong>Topic Assignment</strong><br>
                    LDA model scores each response ‚Üí Assigns primary topic + probability distribution
                </div>
                <div class="pipeline-step">
                    <strong>Trend Analysis</strong><br>
                    Compare month-over-month topic volumes ‚Üí Flag emerging issues or improvements
                </div>
                <div class="pipeline-step">
                    <strong>R Shiny Dashboard</strong><br>
                    Interactive visualization ‚Üí Filter by topic, time period, region, sentiment
                </div>
                <div class="pipeline-step">
                    <strong>Executive Reports</strong><br>
                    Automated monthly PDF ‚Üí Top 5 topics, sentiment breakdown, sample quotes
                </div>
            </div>

            <div class="workflow-diagram">
                <h4>üìä Dashboard Features & Use Cases</h4>

                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Topic Volume Trends</strong><br>
                        <em>Visualization: Line chart showing % of responses per topic over time</em>
                        <em>Insight Example: "Delivery Timeliness" complaints spiked 40% in December (holiday season)</em>
                        <em>Action: Operations team added seasonal drivers proactively for next year</em>
                        <em>Business Value: Transformed reactive firefighting into proactive planning</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Regional Deep-Dives</strong><br>
                        <em>Feature: Filter topics by geographic region (Northeast, Southeast, Midwest, West)</em>
                        <em>Finding: "Product Freshness" complaints 3x higher in West (longer distribution routes)</em>
                        <em>Action: Added refrigerated distribution hub in California</em>
                        <em>Result: West region freshness complaints dropped 35% in 6 months</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Sentiment-Topic Heatmap</strong><br>
                        <em>Visualization: 15 topics √ó 3 sentiments (positive/neutral/negative) heatmap</em>
                        <em>Insight: "Driver Professionalism" overwhelmingly positive (85% positive sentiment)</em>
                        <em>Insight: "Invoice & Billing" overwhelmingly negative (72% negative sentiment)</em>
                        <em>Strategy: Celebrate driver excellence in internal communications, fix billing urgently</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>Representative Quote Extraction</strong><br>
                        <em>Feature: For each topic, display 10 most representative responses</em>
                        <em>Method: Select documents with highest probability for that topic</em>
                        <em>Use Case: Executives want real customer voice, not just statistics</em>
                        <em>Example: "Delivery Timeliness" quote - "Driver arrived 2 hours late with no notification. Missed our prep window."</em>
                    </div>
                </div>
            </div>

            <div class="methodology-box">
                <h4>üîÅ Continuous Improvement Loop</h4>
                <p><strong>Quarterly Model Retraining:</strong></p>
                <ul>
                    <li>Every 3 months, retrain LDA on rolling 12-month window of data</li>
                    <li>Captures evolving customer language and emerging themes</li>
                    <li>Example: "Contactless delivery" emerged as new topic in 2020, disappeared by 2022</li>
                </ul>
                <p><strong>Feedback Mechanism:</strong></p>
                <ul>
                    <li>CX analysts can flag misclassified responses in dashboard</li>
                    <li>Misclassifications reviewed quarterly ‚Üí Inform preprocessing improvements</li>
                    <li>Added 50+ domain-specific stop words based on analyst feedback</li>
                </ul>
            </div>
        </div>

        <div class="impact-section">
            <h2>Business Impact & Results</h2>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-number">2M+</div>
                    <div class="metric-label">Survey Responses Analyzed</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">15</div>
                    <div class="metric-label">Distinct Customer Themes Discovered</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">97%</div>
                    <div class="metric-label">Reduction in Manual Review Time</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">84%</div>
                    <div class="metric-label">Agreement with Human Labeling</div>
                </div>
            </div>

            <h3>Key Business Outcomes</h3>
            <ul>
                <li><strong>Speed to Insight:</strong> Reduced from 8 weeks (manual review) to 2 days (automated topic analysis)</li>
                <li><strong>Coverage:</strong> Analyzed 100% of responses (vs. 1-2% manual sample)</li>
                <li><strong>Discovered Hidden Issue:</strong> Invoice/Billing was #5 complaint theme (previously unknown)</li>
                <li><strong>Regional Optimization:</strong> Identified West region freshness issue ‚Üí Targeted infrastructure investment</li>
                <li><strong>Proactive Planning:</strong> Seasonal staffing adjusted based on predicted "Delivery Timeliness" spikes</li>
                <li><strong>Executive Visibility:</strong> Monthly topic reports used in C-suite CX reviews</li>
                <li><strong>NPS Improvement:</strong> Addressing top 3 topics correlated with 8-point NPS increase over 12 months</li>
            </ul>

            <h3>Key Technical Learnings</h3>
            <ol>
                <li><strong>Preprocessing = 50% of Success:</strong> Bigram detection and custom stop words critical for interpretable topics</li>
                <li><strong>k Selection is Art + Science:</strong> Coherence score guides, but business validation confirms optimal k</li>
                <li><strong>Short Documents Problematic:</strong> <20 words provides insufficient context for LDA (set minimum threshold)</li>
                <li><strong>Topic Stability Validates Model:</strong> Consistent topics across time periods proves model isn't overfitting</li>
                <li><strong>Human-in-the-Loop Essential:</strong> Automated topic discovery + human labeling = best of both worlds</li>
                <li><strong>Sentiment Stratification Useful:</strong> Separate LDA models for positive vs. negative responses revealed different themes</li>
            </ol>

            <h3>LDA vs. Other Methods: Lessons Learned</h3>
            <p><strong>When to Use LDA:</strong> Large text corpus (10K+ documents), need interpretability, unsupervised discovery, computational constraints</p>
            <p><strong>When NOT to Use LDA:</strong> Short texts (<50 words/document), need fine-grained classification, have labeled training data (use supervised learning)</p>
            <p><strong>LDA vs. BERTopic:</strong> BERTopic more accurate (5-10%) but 100x slower and less interpretable (black-box embeddings)</p>
            <p><strong>LDA vs. Rule-Based:</strong> Rules miss emergent themes (e.g., "COVID protocols"); LDA discovers them automatically</p>
        </div>

        <div class="content-section">
            <h2>Tools & Technologies</h2>
            <div class="tech-stack">
                <span class="tech-badge">R</span>
                <span class="tech-badge">Python</span>
                <span class="tech-badge">LDA (Gensim)</span>
                <span class="tech-badge">spaCy</span>
                <span class="tech-badge">NLTK</span>
                <span class="tech-badge">topicmodels (R)</span>
                <span class="tech-badge">R Shiny</span>
                <span class="tech-badge">ggplot2</span>
                <span class="tech-badge">tidytext</span>
                <span class="tech-badge">VADER Sentiment</span>
                <span class="tech-badge">Qualtrics API</span>
                <span class="tech-badge">SQL</span>
            </div>

            <h3>Project Timeline</h3>
            <p><strong>Total Duration:</strong> 7 months (March - September 2021)</p>
            <ul>
                <li>Month 1-2: Data collection, preprocessing pipeline development, EDA</li>
                <li>Month 3: Topic modeling experimentation (k selection, hyperparameter tuning)</li>
                <li>Month 4: Model validation, human agreement studies, topic labeling</li>
                <li>Month 5: R Shiny dashboard development, stakeholder feedback</li>
                <li>Month 6: Production deployment, monthly automation setup</li>
                <li>Month 7: Training sessions, executive presentations, handoff to CX team</li>
            </ul>
        </div>

        <a href="index.html" class="back-button">‚Üê Back to Portfolio</a>
    </div>
</body>
</html>
