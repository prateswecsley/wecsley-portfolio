<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Generative AI Customer Insights - Project Details | Wecsley Prates</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6; color: #333; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 2rem 0; }
        .container { max-width: 1200px; margin: 0 auto; padding: 0 2rem; }
        .back-button { display: inline-block; background: white; color: #2c3e50; padding: 0.8rem 1.5rem; text-decoration: none; border-radius: 5px; margin-bottom: 2rem; font-weight: 600; transition: all 0.3s; box-shadow: 0 4px 15px rgba(0,0,0,0.1); }
        .back-button:hover { transform: translateY(-2px); box-shadow: 0 6px 20px rgba(0,0,0,0.15); }
        .project-header { background: linear-gradient(135deg, #3498db 0%, #2980b9 100%); color: white; padding: 3rem 2rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }
        .project-header h1 { font-size: 2.5rem; margin-bottom: 0.5rem; }
        .project-header .company { font-size: 1.2rem; opacity: 0.9; margin-bottom: 1rem; }
        .project-header .date { font-size: 1rem; opacity: 0.8; }
        .content-section { background: white; padding: 2.5rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 5px 20px rgba(0,0,0,0.1); }
        .content-section h2 { color: #2c3e50; font-size: 1.8rem; margin-bottom: 1.5rem; padding-bottom: 0.5rem; border-bottom: 3px solid #3498db; }
        .content-section h3 { color: #34495e; font-size: 1.4rem; margin-top: 1.5rem; margin-bottom: 1rem; }
        .content-section h4 { color: #7f8c8d; font-size: 1.1rem; margin-top: 1rem; margin-bottom: 0.5rem; }
        .content-section p { margin-bottom: 1rem; text-align: justify; }
        .content-section ul, .content-section ol { margin-left: 2rem; margin-bottom: 1rem; }
        .content-section li { margin-bottom: 0.5rem; }
        .highlight-box { background: #f8f9fa; border-left: 4px solid #3498db; padding: 1.5rem; margin: 1.5rem 0; border-radius: 5px; }
        .tech-stack { display: flex; flex-wrap: wrap; gap: 0.8rem; margin: 1rem 0; }
        .tech-badge { background: linear-gradient(135deg, #3498db, #2980b9); color: white; padding: 0.5rem 1rem; border-radius: 20px; font-size: 0.9rem; font-weight: 600; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        .metrics-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1.5rem; margin: 2rem 0; }
        .metric-card { background: linear-gradient(135deg, #27ae60, #229954); color: white; padding: 1.5rem; border-radius: 10px; text-align: center; box-shadow: 0 5px 15px rgba(0,0,0,0.1); }
        .metric-number { font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem; }
        .metric-label { font-size: 1rem; opacity: 0.9; }
        .code-block { background: #2c3e50; color: #ecf0f1; padding: 1.5rem; border-radius: 8px; overflow-x: auto; margin: 1rem 0; font-family: 'Courier New', monospace; font-size: 0.9rem; line-height: 1.5; }
        .data-flow { background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); padding: 2rem; border-radius: 10px; margin: 1.5rem 0; }
        .flow-step { display: flex; align-items: center; margin: 1rem 0; padding: 1rem; background: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }
        .flow-step .step-number { background: #3498db; color: white; width: 40px; height: 40px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; margin-right: 1rem; flex-shrink: 0; }
        .impact-section { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 2.5rem; border-radius: 15px; margin-top: 2rem; }
        .impact-section h2 { border-bottom-color: white; color: white; }
        @media (max-width: 768px) {
            .project-header h1 { font-size: 2rem; }
            .content-section { padding: 1.5rem; }
            .metrics-grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="index.html" class="back-button">‚Üê Back to Portfolio</a>

        <div class="project-header">
            <h1>ü§ñ Generative AI Customer Insights</h1>
            <div class="company">LexisNexis Risk Solutions</div>
            <div class="date">January 2021 - April 2024 | Alpharetta, GA</div>
        </div>

        <!-- Continue with full detailed content similar to the Markov project -->
        <div class="content-section">
            <h2>Project Overview</h2>
            <p>
                This innovative project involved fine-tuning Large Language Models (LLMs) specifically BERT and GPT models to automate the analysis and summarization of customer feedback at scale. The goal was to process over 100,000 monthly feedback entries from surveys, support tickets, and reviews to extract actionable insights for marketing, product development, and customer support teams.
            </p>
            <div class="highlight-box">
                <strong>Challenge:</strong> Manual processing of thousands of customer feedback entries was time-consuming, inconsistent, and prevented real-time insights that could improve customer experience and drive product improvements.
            </div>
        </div>

        <div class="content-section">
            <h2>Business Problem & Context</h2>
            <h3>The Challenge</h3>
            <p>LexisNexis Risk Solutions received massive volumes of unstructured text data daily:</p>
            <ul>
                <li>100,000+ customer feedback entries monthly</li>
                <li>Multiple sources: NPS surveys, support tickets, product reviews, webforms</li>
                <li>Mixed sentiment and unstructured content</li>
                <li>Manual review taking 40+ hours weekly across teams</li>
                <li>Delayed insights (2-3 weeks lag from feedback to action)</li>
            </ul>

            <h3>Business Impact Need</h3>
            <p>The organization needed to:</p>
            <ul>
                <li>Identify recurring customer pain points quickly</li>
                <li>Detect emerging issues before they escalate</li>
                <li>Extract product improvement opportunities</li>
                <li>Generate automated summaries for executive reporting</li>
                <li>Personalize marketing based on customer sentiment</li>
            </ul>
        </div>

        <div class="content-section">
            <h2>Phase 1: Data Collection & Preparation</h2>
            
            <h3>1.1 Data Sources</h3>
            <div class="tech-stack">
                <span class="tech-badge">Qualtrics (NPS Surveys)</span>
                <span class="tech-badge">Zendesk (Support Tickets)</span>
                <span class="tech-badge">Trustpilot (Reviews)</span>
                <span class="tech-badge">Website Forms</span>
                <span class="tech-badge">Email Responses</span>
            </div>

            <h3>1.2 Data Extraction Process</h3>
            <div class="code-block">
# Python script for data extraction
import pandas as pd
from datetime import datetime, timedelta
import requests
from sqlalchemy import create_engine

def extract_feedback_data(days_back=30):
    """Extract customer feedback from multiple sources"""
    
    # Qualtrics API for NPS surveys
    qualtrics_data = extract_qualtrics_surveys(days_back)
    
    # Zendesk API for support tickets
    zendesk_data = extract_zendesk_tickets(days_back)
    
    # Web scraping for public reviews
    review_data = extract_online_reviews(days_back)
    
    # Combine all sources
    all_feedback = pd.concat([
        qualtrics_data,
        zendesk_data,
        review_data
    ], ignore_index=True)
    
    return all_feedback

def extract_qualtrics_surveys(days_back):
    api_token = os.getenv('QUALTRICS_API_TOKEN')
    datacenter = 'yourDatacenterID'
    survey_id = 'yourSurveyID'
    
    url = f"https://{datacenter}.qualtrics.com/API/v3/surveys/{survey_id}/responses"
    headers = {"X-API-TOKEN": api_token}
    
    response = requests.get(url, headers=headers)
    data = response.json()
    
    # Parse responses into structured format
    feedback_list = []
    for response in data['result']['responses']:
        feedback_list.append({
            'feedback_id': response['responseId'],
            'timestamp': response['endDate'],
            'source': 'NPS Survey',
            'text': response['values']['QID1_TEXT'],  # Open-ended question
            'nps_score': int(response['values']['QID2']),  # NPS rating
            'customer_id': response['values']['externalDataReference']
        })
    
    return pd.DataFrame(feedback_list)
            </div>

            <h3>1.3 Data Preprocessing</h3>
            <div class="code-block">
# R script for text preprocessing
library(tidyverse)
library(tm)
library(textclean)

preprocess_feedback <- function(raw_text) {
  
  cleaned_text <- raw_text %>%
    # Convert to lowercase
    tolower() %>%
    
    # Remove URLs
    str_replace_all("http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", "") %>%
    
    # Remove email addresses
    str_replace_all("\\S+@\\S+", "") %>%
    
    # Remove special characters but keep basic punctuation
    str_replace_all("[^[:alnum:][:space:].,!?-]", "") %>%
    
    # Remove extra whitespace
    str_squish() %>%
    
    # Fix common contractions
    replace_contraction() %>%
    
    # Remove stopwords (careful not to remove sentiment-critical words)
    removeWords(c("um", "uh", "like", "you know"))
  
  return(cleaned_text)
}

# Apply preprocessing
feedback_data <- feedback_data %>%
  mutate(
    text_clean = map_chr(text, preprocess_feedback),
    word_count = str_count(text_clean, "\\w+"),
    char_count = nchar(text_clean)
  ) %>%
  # Filter out very short feedback (< 10 words)
  filter(word_count >= 10)
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 2: Exploratory Data Analysis</h2>

            <h3>2.1 Text Statistics</h3>
            <div class="code-block">
# Analyze text characteristics
library(tidytext)

# Tokenization and word frequency
word_freq <- feedback_data %>%
  unnest_tokens(word, text_clean) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE)

# Most common words
top_words <- word_freq %>%
  top_n(50) %>%
  ggplot(aes(x = reorder(word, n), y = n)) +
  geom_col(fill = "#3498db") +
  coord_flip() +
  labs(title = "Top 50 Most Frequent Words in Customer Feedback",
       x = "Word", y = "Frequency")

# Sentiment analysis
library(tidytext)
sentiment_scores <- feedback_data %>%
  unnest_tokens(word, text_clean) %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(feedback_id) %>%
  summarise(
    sentiment_score = sum(value),
    sentiment_words = n()
  )

# Correlate with NPS scores
cor(sentiment_scores$sentiment_score, feedback_data$nps_score)
# Result: 0.72 correlation (strong positive relationship)
            </div>

            <h3>2.2 Key Findings from EDA</h3>
            <div class="highlight-box">
                <ul>
                    <li>Average feedback length: 87 words</li>
                    <li>Peak feedback times: Monday mornings, Friday afternoons</li>
                    <li>Top topics: "customer service" (18%), "pricing" (15%), "features" (12%)</li>
                    <li>Negative feedback was 2.3x longer than positive feedback</li>
                    <li>72% of feedback contained actionable suggestions</li>
                </ul>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 3: Model Development - Fine-Tuning LLMs</h2>

            <h3>3.1 Model Selection</h3>
            <p>I evaluated multiple LLM architectures:</p>
            <ul>
                <li><strong>BERT (facebook/bart-large-cnn):</strong> For summarization tasks</li>
                <li><strong>GPT-3.5-turbo:</strong> For text generation and sentiment analysis</li>
                <li><strong>DistilBERT:</strong> For classification (positive/neutral/negative)</li>
            </ul>

            <h3>3.2 Fine-Tuning Process</h3>
            <div class="code-block">
# Python - Fine-tuning BERT for summarization
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments
import torch

# Load pre-trained model and tokenizer
model_name = "facebook/bart-large-cnn"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# Prepare training data
def prepare_data(feedback_df):
    # Create input-target pairs
    # Input: original feedback text
    # Target: human-written summaries (from labeled subset)
    
    inputs = tokenizer(
        feedback_df['text_clean'].tolist(),
        max_length=512,
        truncation=True,
        padding='max_length',
        return_tensors='pt'
    )
    
    targets = tokenizer(
        feedback_df['summary'].tolist(),  # Human-labeled summaries
        max_length=128,
        truncation=True,
        padding='max_length',
        return_tensors='pt'
    )
    
    return inputs, targets

# Training arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=4,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=100,
    evaluation_strategy="steps",
    eval_steps=500,
    save_steps=1000,
    load_best_model_at_end=True
)

# Initialize Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    tokenizer=tokenizer
)

# Fine-tune the model
trainer.train()

# Save fine-tuned model
model.save_pretrained('./fine_tuned_bert_summarizer')
tokenizer.save_pretrained('./fine_tuned_bert_summarizer')
            </div>

            <h3>3.3 Integration with R using Reticulate</h3>
            <div class="code-block">
# R script - Using fine-tuned model via reticulate
library(reticulate)

# Configure Python environment
use_condaenv("nlp_env")

# Import Python libraries
transformers <- import("transformers")
torch <- import("torch")

# Load fine-tuned model
load_model <- function() {
  model_path <- "./fine_tuned_bert_summarizer"
  
  tokenizer <- transformers$AutoTokenizer$from_pretrained(model_path)
  model <- transformers$AutoModelForSeq2SeqLM$from_pretrained(model_path)
  
  return(list(tokenizer = tokenizer, model = model))
}

# Generate summary function
generate_summary <- function(text, model, tokenizer) {
  # Tokenize input
  inputs <- tokenizer(
    text,
    max_length = 512L,
    truncation = TRUE,
    return_tensors = "pt"
  )
  
  # Generate summary
  summary_ids <- model$generate(
    inputs$input_ids,
    max_length = 128L,
    min_length = 30L,
    length_penalty = 2.0,
    num_beams = 4L,
    early_stopping = TRUE
  )
  
  # Decode summary
  summary <- tokenizer$decode(summary_ids[[1]], skip_special_tokens = TRUE)
  
  return(summary)
}

# Process all feedback
model_components <- load_model()

feedback_with_summaries <- feedback_data %>%
  mutate(
    ai_summary = map_chr(text_clean, 
                        ~generate_summary(., 
                                        model_components$model,
                                        model_components$tokenizer))
  )
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 4: Implementation & Deployment</h2>

            <h3>4.1 API Development</h3>
            <div class="code-block">
# FastAPI deployment for model serving
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from transformers import pipeline

app = FastAPI()

# Load model once at startup
summarizer = pipeline("summarization", model="./fine_tuned_bert_summarizer")
sentiment_analyzer = pipeline("sentiment-analysis", model="./fine_tuned_sentiment_model")

class FeedbackRequest(BaseModel):
    text: str
    include_sentiment: bool = True

class FeedbackResponse(BaseModel):
    summary: str
    sentiment: str = None
    confidence: float = None

@app.post("/analyze_feedback", response_model=FeedbackResponse)
async def analyze_feedback(request: FeedbackRequest):
    try:
        # Generate summary
        summary_result = summarizer(request.text, max_length=128, min_length=30)
        summary = summary_result[0]['summary_text']
        
        # Analyze sentiment if requested
        sentiment = None
        confidence = None
        if request.include_sentiment:
            sentiment_result = sentiment_analyzer(request.text)[0]
            sentiment = sentiment_result['label']
            confidence = sentiment_result['score']
        
        return FeedbackResponse(
            summary=summary,
            sentiment=sentiment,
            confidence=confidence
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Health check endpoint
@app.get("/health")
async def health_check():
    return {"status": "healthy"}

# Run with: uvicorn api:app --host 0.0.0.0 --port 8000
            </div>

            <h3>4.2 R Integration with API</h3>
            <div class="code-block">
# R script - Call the FastAPI endpoint
library(httr)
library(jsonlite)

analyze_feedback_api <- function(text) {
  
  api_url <- "http://localhost:8000/analyze_feedback"
  
  response <- POST(
    api_url,
    body = list(
      text = text,
      include_sentiment = TRUE
    ),
    encode = "json"
  )
  
  if (status_code(response) == 200) {
    result <- content(response, as = "parsed")
    return(result)
  } else {
    stop("API request failed")
  }
}

# Process feedback in batches
process_batch <- function(feedback_batch) {
  results <- feedback_batch %>%
    mutate(
      api_result = map(text_clean, possibly(analyze_feedback_api, NULL)),
      ai_summary = map_chr(api_result, ~.x$summary %||% NA_character_),
      sentiment = map_chr(api_result, ~.x$sentiment %||% NA_character_),
      confidence = map_dbl(api_result, ~.x$confidence %||% NA_real_)
    )
  
  return(results)
}
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 5: Automation & Reporting</h2>

            <h3>5.1 Automated Weekly Report Generation</h3>
            <div class="code-block">
# R Markdown automated report
library(rmarkdown)
library(knitr)

generate_weekly_insights_report <- function() {
  
  # Process last week's feedback
  last_week_feedback <- get_feedback_data(days_back = 7)
  
  # Analyze with AI
  analyzed_feedback <- process_batch(last_week_feedback)
  
  # Extract key themes
  themes <- extract_themes(analyzed_feedback$ai_summary)
  
  # Generate insights
  insights <- list(
    total_feedback = nrow(analyzed_feedback),
    avg_sentiment_score = mean(analyzed_feedback$confidence, na.rm = TRUE),
    top_themes = themes %>% head(10),
    trending_issues = identify_trending_issues(analyzed_feedback),
    actionable_recommendations = generate_recommendations(analyzed_feedback)
  )
  
  # Render R Markdown report
  render(
    "weekly_insights_template.Rmd",
    output_file = paste0("weekly_insights_", Sys.Date(), ".html"),
    params = list(insights = insights)
  )
  
  # Send to stakeholders
  send_email_report(paste0("weekly_insights_", Sys.Date(), ".html"))
}

# Schedule to run every Monday
library(taskscheduleR)
taskscheduler_create(
  taskname = "weekly_insights",
  rscript = "generate_weekly_insights_report.R",
  schedule = "WEEKLY",
  starttime = "06:00",
  days = "MON"
)
            </div>

            <h3>5.2 Real-Time Dashboard</h3>
            <p>Created an R Shiny dashboard for real-time monitoring:</p>
            <ul>
                <li>Live feed of recent feedback with AI summaries</li>
                <li>Sentiment trend charts over time</li>
                <li>Topic clustering visualization</li>
                <li>Alert system for negative sentiment spikes</li>
                <li>Drill-down capability by product, region, customer segment</li>
            </ul>
        </div>

        <div class="impact-section">
            <h2>Business Results & Impact</h2>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-number">27%</div>
                    <div class="metric-label">Improvement in Summarization Accuracy</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">100K+</div>
                    <div class="metric-label">Feedback Entries Processed Monthly</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">15%</div>
                    <div class="metric-label">Increase in NPS Scores</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">95%</div>
                    <div class="metric-label">Time Saved on Manual Review</div>
                </div>
            </div>

            <h3>Key Achievements</h3>
            <ul>
                <li>Reduced manual feedback review time from 40 hours/week to 2 hours/week</li>
                <li>Enabled real-time issue detection (vs. 2-3 week lag)</li>
                <li>Identified 23 product improvements implemented in 6 months</li>
                <li>Improved customer support response time by 34%</li>
                <li>Generated automated executive summaries saving 10 hours/month</li>
            </ul>
        </div>

        <div class="content-section">
            <h2>Tools & Technologies</h2>
            <div class="tech-stack">
                <span class="tech-badge">Python</span>
                <span class="tech-badge">R</span>
                <span class="tech-badge">Transformers (Hugging Face)</span>
                <span class="tech-badge">PyTorch</span>
                <span class="tech-badge">BERT</span>
                <span class="tech-badge">GPT-3.5</span>
                <span class="tech-badge">FastAPI</span>
                <span class="tech-badge">R Shiny</span>
                <span class="tech-badge">reticulate</span>
                <span class="tech-badge">tidytext</span>
                <span class="tech-badge">Power BI</span>
                <span class="tech-badge">AWS</span>
            </div>
        </div>

        <a href="index.html" class="back-button">‚Üê Back to Portfolio</a>
    </div>
</body>
</html>
