<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <title>Loan Default Classification - Methodology | Wecsley Prates</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; line-height: 1.6; color: #333; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 2rem 0; }
        .container { max-width: 1200px; margin: 0 auto; padding: 0 2rem; }
        .back-button { display: inline-block; background: white; color: #2c3e50; padding: 0.8rem 1.5rem; text-decoration: none; border-radius: 5px; margin-bottom: 2rem; font-weight: 600; transition: all 0.3s; box-shadow: 0 4px 15px rgba(0,0,0,0.1); }
        .back-button:hover { transform: translateY(-2px); box-shadow: 0 6px 20px rgba(0,0,0,0.15); }
        .project-header { background: linear-gradient(135deg, #f39c12 0%, #d68910 100%); color: white; padding: 3rem 2rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }
        .project-header h1 { font-size: 2.5rem; margin-bottom: 0.5rem; }
        .project-header .company { font-size: 1.2rem; opacity: 0.9; margin-bottom: 1rem; }
        .project-header .date { font-size: 1rem; opacity: 0.8; }
        .content-section { background: white; padding: 2.5rem; border-radius: 15px; margin-bottom: 2rem; box-shadow: 0 5px 20px rgba(0,0,0,0.1); }
        .content-section h2 { color: #2c3e50; font-size: 1.8rem; margin-bottom: 1.5rem; padding-bottom: 0.5rem; border-bottom: 3px solid #f39c12; }
        .content-section h3 { color: #34495e; font-size: 1.4rem; margin-top: 1.5rem; margin-bottom: 1rem; }
        .content-section h4 { color: #7f8c8d; font-size: 1.1rem; margin-top: 1rem; margin-bottom: 0.5rem; }
        .content-section p { margin-bottom: 1rem; text-align: justify; }
        .content-section ul, .content-section ol { margin-left: 2rem; margin-bottom: 1rem; }
        .content-section li { margin-bottom: 0.5rem; }
        .highlight-box { background: #f8f9fa; border-left: 4px solid #f39c12; padding: 1.5rem; margin: 1.5rem 0; border-radius: 5px; }
        .tech-stack { display: flex; flex-wrap: wrap; gap: 0.8rem; margin: 1rem 0; }
        .tech-badge { background: linear-gradient(135deg, #f39c12, #d68910); color: white; padding: 0.5rem 1rem; border-radius: 20px; font-size: 0.9rem; font-weight: 600; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
        .metrics-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1.5rem; margin: 2rem 0; }
        .metric-card { background: linear-gradient(135deg, #3498db, #2980b9); color: white; padding: 1.5rem; border-radius: 10px; text-align: center; box-shadow: 0 5px 15px rgba(0,0,0,0.1); }
        .metric-number { font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem; }
        .metric-label { font-size: 1rem; opacity: 0.9; }
        .workflow-diagram { background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); padding: 2rem; border-radius: 10px; margin: 1.5rem 0; border: 2px solid #f39c12; }
        .workflow-diagram h4 { color: #f39c12; margin-bottom: 1.5rem; font-size: 1.3rem; text-align: center; }
        .flow-step { display: flex; align-items: flex-start; margin: 1.5rem 0; padding: 1.5rem; background: white; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); border-left: 4px solid #f39c12; }
        .flow-step .step-number { background: #f39c12; color: white; width: 45px; height: 45px; border-radius: 50%; display: flex; align-items: center; justify-content: center; font-weight: bold; font-size: 1.2rem; margin-right: 1.5rem; flex-shrink: 0; }
        .flow-step strong { color: #2c3e50; display: block; margin-bottom: 0.5rem; font-size: 1.1rem; }
        .flow-step em { color: #7f8c8d; font-style: normal; display: block; margin: 0.3rem 0; }
        .flow-step em:before { content: '‚Üí '; color: #f39c12; font-weight: bold; }
        .pipeline-visual { background: white; padding: 2rem; border-radius: 10px; margin: 2rem 0; border: 2px solid #3498db; }
        .pipeline-visual h4 { color: #3498db; text-align: center; margin-bottom: 1.5rem; }
        .pipeline-step { background: linear-gradient(135deg, #3498db, #2980b9); color: white; padding: 1rem 1.5rem; border-radius: 8px; margin: 1rem 0; position: relative; }
        .pipeline-step:not(:last-child):after { content: '‚ñº'; display: block; text-align: center; color: #3498db; font-size: 2rem; margin: 0.5rem 0; }
        .methodology-box { background: #fff3cd; border-left: 4px solid #f39c12; padding: 1.5rem; margin: 1.5rem 0; border-radius: 5px; }
        .methodology-box h4 { color: #f39c12; margin-bottom: 0.8rem; }
        .decision-box { background: #d1ecf1; border-left: 4px solid #17a2b8; padding: 1.5rem; margin: 1.5rem 0; border-radius: 5px; }
        .decision-box h4 { color: #17a2b8; margin-bottom: 0.8rem; }
        .impact-section { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 2.5rem; border-radius: 15px; margin-top: 2rem; }
        .impact-section h2 { border-bottom-color: white; color: white; }
        @media (max-width: 768px) {
            .project-header h1 { font-size: 2rem; }
            .content-section { padding: 1.5rem; }
            .metrics-grid { grid-template-columns: 1fr; }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="index.html" class="back-button">‚Üê Back to Portfolio</a>

        <div class="project-header">
            <h1>üí≥ Loan Default Classification System</h1>
            <div class="company">M&T Bank</div>
            <div class="date">January 2023 - May 2023 | Buffalo, NY</div>
        </div>

        <div class="content-section">
            <h2>Project Overview</h2>
            <p>
                Built a production-grade machine learning system to predict loan defaults with 91.3% accuracy, processing 50,000+ monthly loan applications at M&T Bank. The XGBoost-based model reduced default rates by 12% through better risk assessment while maintaining approval rates, saving the bank an estimated $4.2M annually in bad debt write-offs.
            </p>
            <div class="highlight-box">
                <strong>The Challenge:</strong> M&T Bank's legacy credit scoring system (rules-based) had two critical flaws: (1) High false negative rate‚Äîapproved 8.5% of loans that later defaulted, costing millions in losses; (2) Oversimplified risk assessment‚Äîbinary approve/deny based on FICO score alone, missing nuanced patterns in customer behavior, employment history, and debt-to-income ratios.
            </div>
        </div>

        <div class="content-section">
            <h2>üìä Methodology & Workflow</h2>
            
            <div class="pipeline-visual">
                <h4>End-to-End ML Pipeline</h4>
                <div class="pipeline-step">
                    <strong>Phase 1: Data Collection & Understanding</strong><br>
                    Historical loan data (2018-2022) ‚Üí 200K loans ‚Üí 50 features ‚Üí Target: Default (Yes/No)
                </div>
                <div class="pipeline-step">
                    <strong>Phase 2: Feature Engineering</strong><br>
                    Credit utilization ratios ‚Üí Debt-to-income ‚Üí Payment history patterns ‚Üí Engineered 25 new features
                </div>
                <div class="pipeline-step">
                    <strong>Phase 3: Model Selection & Training</strong><br>
                    XGBoost chosen ‚Üí Hyperparameter tuning ‚Üí Class imbalance handling ‚Üí Cross-validation
                </div>
                <div class="pipeline-step">
                    <strong>Phase 4: Model Validation & Calibration</strong><br>
                    Precision-recall optimization ‚Üí Threshold tuning ‚Üí Fairness testing ‚Üí Regulatory compliance
                </div>
                <div class="pipeline-step">
                    <strong>Phase 5: Production Deployment</strong><br>
                    API integration ‚Üí Real-time scoring ‚Üí Monitoring dashboards ‚Üí A/B testing
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 1: Data Collection & Problem Definition</h2>
            
            <div class="methodology-box">
                <h4>üí° Defining Success: The Cost-Benefit Framework</h4>
                <p><strong>Question:</strong> What does "good" model performance mean for a loan classifier?</p>
                <p><strong>Business Reality:</strong> Two types of errors have different costs:</p>
                <ul>
                    <li><strong>False Positive (predict default, but customer pays):</strong> Lost revenue from rejected loan (~$500 profit per loan)</li>
                    <li><strong>False Negative (approve loan, customer defaults):</strong> Bad debt write-off (~$8,000 average loan loss)</li>
                </ul>
                <p><strong>Implication:</strong> False negatives cost 16x more than false positives ‚Üí Model must prioritize recall (catching defaults)</p>
                <p><strong>Target Metric:</strong> Minimize false negative rate while maintaining 75% approval rate (business constraint)</p>
            </div>

            <div class="workflow-diagram">
                <h4>üîÑ Data Collection Workflow</h4>
                
                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Loan Application Data (Core Features)</strong><br>
                        <em>Source: Loan origination system (2018-2022, 200K loans)</em>
                        <em>Features: Loan amount, loan term, interest rate, purpose (home, auto, personal)</em>
                        <em>Applicant Data: Annual income, employment length, home ownership status</em>
                        <em>Credit Data: FICO score, number of credit lines, total credit limit</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Payment History (Target Variable)</strong><br>
                        <em>Definition: Loan labeled "default" if 90+ days past due or charged off</em>
                        <em>Historical Default Rate: 8.5% (17,000 defaults out of 200K loans)</em>
                        <em>Time Lag: Required 24 months of loan history to label (new loans excluded)</em>
                        <em>Challenge: Class imbalance (91.5% non-default, 8.5% default)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>External Credit Bureau Data</strong><br>
                        <em>Source: Experian credit reports (pulled at application time)</em>
                        <em>Features: Number of delinquencies, public records (bankruptcies), credit inquiries (last 6 months)</em>
                        <em>Why Critical: Bank's internal data doesn't show customer behavior at other lenders</em>
                        <em>Integration: Matched via SSN to loan applications</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>Data Quality Assessment</strong><br>
                        <em>Missing Data: 12% of records missing employment length ‚Üí Imputation needed</em>
                        <em>Outliers: Found 350 loans with income >$10M (data entry errors) ‚Üí Capped at 99th percentile</em>
                        <em>Inconsistencies: 2,100 loans had debt-to-income >1.0 (impossible) ‚Üí Investigated and corrected</em>
                        <em>Final Clean Dataset: 192,000 loans (96% of original)</em>
                    </div>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 2: Feature Engineering Strategy</h2>

            <div class="decision-box">
                <h4>üéØ Feature Engineering Philosophy</h4>
                <p><strong>Goal:</strong> Transform raw data into signals that predict default risk</p>
                <p><strong>Approach:</strong> Domain expertise + exploratory analysis ‚Üí Create features lenders actually use</p>
                <p><strong>Example:</strong> Raw data has "Total credit limit" and "Total credit used"</p>
                <p><strong>Engineered Feature:</strong> Credit Utilization Ratio = Used / Limit (more predictive than raw values)</p>
            </div>

            <div class="workflow-diagram">
                <h4>‚öôÔ∏è Feature Creation Process</h4>

                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Debt-to-Income Ratio (DTI)</strong><br>
                        <em>Formula: (Loan Payment + Other Debt Payments) / Monthly Income</em>
                        <em>Why Important: High DTI indicates customer overextended financially</em>
                        <em>Finding: DTI >0.43 ‚Üí 3x higher default rate than DTI <0.30</em>
                        <em>Treatment: Binned into 5 categories (Conservative, Moderate, Aggressive, Very High, Extreme)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Credit Utilization Ratio</strong><br>
                        <em>Formula: Total Credit Card Balances / Total Credit Limits</em>
                        <em>Interpretation: >80% utilization signals financial stress (maxing out cards)</em>
                        <em>Finding: Utilization >80% ‚Üí 2.5x higher default rate</em>
                        <em>Decision: Created binary flag "High Utilization" (>80%) as additional feature</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Payment-to-Income Ratio</strong><br>
                        <em>Formula: Monthly Loan Payment / Monthly Gross Income</em>
                        <em>Threshold: Federal guidelines suggest <28% for housing, <36% total debt</em>
                        <em>Finding: Payment >20% of income ‚Üí Default rate jumps from 5% to 18%</em>
                        <em>Use Case: Identifies affordable loan amounts for each applicant</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>Recent Credit Behavior Flags</strong><br>
                        <em>Feature: Number of hard inquiries in last 6 months</em>
                        <em>Interpretation: >6 inquiries suggests "credit shopping" (desperation for credit)</em>
                        <em>Feature: Delinquency in past 2 years (binary flag)</em>
                        <em>Finding: Any past delinquency ‚Üí 4x higher default rate (strongest single predictor)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">5</div>
                    <div>
                        <strong>Employment Stability Score</strong><br>
                        <em>Combined: Employment length + income level + home ownership</em>
                        <em>Rationale: Stable employment (5+ years) + homeowner ‚Üí Lower default risk</em>
                        <em>Creation: Weighted composite score (0-100)</em>
                        <em>Validation: Score correlated -0.42 with default rate (strong negative relationship)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">6</div>
                    <div>
                        <strong>Loan Purpose Risk Adjustment</strong><br>
                        <em>Analysis: Default rates vary by loan purpose</em>
                        <em>Findings: Small business loans (14.2% default) > Personal loans (9.1%) > Auto loans (5.3%)</em>
                        <em>Feature: One-hot encoded loan purpose with risk weights</em>
                        <em>Application: Model learns different risk profiles for different loan types</em>
                    </div>
                </div>
            </div>

            <div class="methodology-box">
                <h4>üìä Feature Selection: From 75 to 32 Features</h4>
                <p><strong>Initial Feature Set:</strong> 50 raw features + 25 engineered = 75 total</p>
                <p><strong>Problem:</strong> Too many features ‚Üí Overfitting risk + slower inference</p>
                <p><strong>Selection Method:</strong></p>
                <ol>
                    <li>Remove features with >40% missing data (e.g., "employer phone number")</li>
                    <li>Correlation analysis: Remove highly correlated pairs (r>0.85) to avoid redundancy</li>
                    <li>Feature importance: Train preliminary model, keep top 32 features by SHAP values</li>
                    <li>Business validation: Ensure final features align with lending best practices</li>
                </ol>
                <p><strong>Result:</strong> 32 features achieved 91% accuracy (vs. 91.1% with all 75) ‚Üí Simpler is better</p>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 3: Model Selection & Training</h2>

            <div class="decision-box">
                <h4>üß† Why XGBoost Over Other Algorithms?</h4>
                <p><strong>Algorithms Evaluated:</strong> Logistic Regression, Random Forest, XGBoost, LightGBM, Neural Network</p>
                <p><strong>Evaluation Results (5-Fold Cross-Validation):</strong></p>
                <ul>
                    <li><strong>Logistic Regression:</strong> 83.2% accuracy, 71% recall ‚Üí Too simple, linear assumptions violated</li>
                    <li><strong>Random Forest:</strong> 89.1% accuracy, 82% recall ‚Üí Good but slower, less interpretable</li>
                    <li><strong>XGBoost:</strong> 91.3% accuracy, 87% recall ‚Üí Best performance, interpretable, fast inference</li>
                    <li><strong>LightGBM:</strong> 91.0% accuracy, 86% recall ‚Üí Marginally worse than XGBoost</li>
                    <li><strong>Neural Network:</strong> 90.5% accuracy, 84% recall ‚Üí Black box, regulatory concerns</li>
                </ul>
                <p><strong>Why XGBoost Won:</strong></p>
                <ul>
                    <li>‚úì Highest recall (87% of defaults caught) - Critical for loss prevention</li>
                    <li>‚úì Built-in feature importance (SHAP values) - Regulatory explainability requirement</li>
                    <li>‚úì Handles class imbalance well (via scale_pos_weight parameter)</li>
                    <li>‚úì Fast inference (<10ms per prediction) - Real-time requirement</li>
                    <li>‚úì Proven track record in financial services</li>
                </ul>
            </div>

            <div class="workflow-diagram">
                <h4>üî¨ XGBoost Training Workflow</h4>

                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Train-Test Split Strategy</strong><br>
                        <em>Method: Time-based split (not random) to prevent data leakage</em>
                        <em>Training: 2018-2021 loans (150K loans)</em>
                        <em>Validation: Jan-Jun 2022 (20K loans)</em>
                        <em>Test: Jul-Dec 2022 (22K loans - completely held out)</em>
                        <em>Rationale: Model must predict future loans, not just similar past loans</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Class Imbalance Handling</strong><br>
                        <em>Problem: 91.5% non-default, 8.5% default ‚Üí Model biased toward majority class</em>
                        <em>Solution: scale_pos_weight = 10.8 (ratio of negative to positive class)</em>
                        <em>Effect: Penalizes model 10.8x more for misclassifying defaults</em>
                        <em>Alternative Rejected: SMOTE oversampling (synthetic data not representative of real applicants)</em>
                        <em>Result: Recall improved from 68% to 87% with scale_pos_weight</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Hyperparameter Optimization</strong><br>
                        <em>Method: Bayesian optimization (Optuna library, 200 trials)</em>
                        <em>Parameters Tuned: max_depth, learning_rate, n_estimators, min_child_weight, subsample, colsample_bytree</em>
                        <em>Objective: Maximize recall subject to precision >75% (business constraint)</em>
                        <em>Optimal Configuration:</em>
                        <em>  ‚Ä¢ max_depth=6 (prevents overfitting), learning_rate=0.05 (stable convergence)</em>
                        <em>  ‚Ä¢ n_estimators=500 (early stopping at iteration 437)</em>
                        <em>  ‚Ä¢ subsample=0.8, colsample_bytree=0.8 (regularization via sampling)</em>
                        <em>Training Time: 12 minutes on 16-core server</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>Feature Interaction Discovery</strong><br>
                        <em>XGBoost Advantage: Automatically learns feature interactions (e.g., high DTI + low FICO = extreme risk)</em>
                        <em>Top Interaction: DTI √ó FICO score (when both bad, default rate 35%)</em>
                        <em>SHAP Analysis: Delinquency history most important feature (SHAP value 0.23)</em>
                        <em>Insight: FICO score alone (legacy system) misses 40% of predictive signal</em>
                    </div>
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 4: Model Validation & Threshold Optimization</h2>

            <div class="methodology-box">
                <h4>‚öñÔ∏è The Precision-Recall Trade-off</h4>
                <p><strong>Challenge:</strong> XGBoost outputs probability (0-1), but we need binary decision (approve/deny)</p>
                <p><strong>Question:</strong> What probability threshold to use? (Default is 0.5, but is that optimal?)</p>
                <p><strong>Business Constraints:</strong></p>
                <ul>
                    <li>Maintain 75% approval rate (can't reject everyone)</li>
                    <li>Minimize false negatives (defaults cost $8K each)</li>
                    <li>Maximize profit: ($500 profit per good loan) - ($8K loss per default)</li>
                </ul>
            </div>

            <div class="workflow-diagram">
                <h4>üéØ Threshold Optimization Process</h4>

                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Precision-Recall Curve Analysis</strong><br>
                        <em>Tested: Thresholds from 0.05 to 0.95 in 0.05 increments</em>
                        <em>Threshold 0.30: 95% recall, 72% precision ‚Üí Catches most defaults but many false positives</em>
                        <em>Threshold 0.50: 87% recall, 81% precision ‚Üí Balanced</em>
                        <em>Threshold 0.70: 73% recall, 89% precision ‚Üí Conservative, misses defaults</em>
                        <em>Decision: Chose 0.42 threshold ‚Üí 87% recall, 78% precision (optimal profit)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Profit Maximization Calculation</strong><br>
                        <em>Formula: Profit = (True Negatives √ó $500) - (False Negatives √ó $8,000) - (False Positives √ó $500 opportunity cost)</em>
                        <em>Threshold 0.42 maximizes expected profit: $2.1M per 50K applications</em>
                        <em>Comparison to Legacy System: +$350K monthly profit improvement</em>
                        <em>Sensitivity Analysis: Robust across ¬±$2K changes in default cost assumption</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Fairness & Bias Testing</strong><br>
                        <em>Regulatory Requirement: Equal Credit Opportunity Act (ECOA) compliance</em>
                        <em>Test: Measured approval rates across protected classes (race, gender, age)</em>
                        <em>Finding: No significant disparate impact (approval rate variance <5% across groups)</em>
                        <em>Removed Features: Zip code (proxy for race), excluded to ensure fairness</em>
                        <em>Audit: External legal review confirmed model compliant with fair lending laws</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>Holdout Test Set Performance</strong><br>
                        <em>Final Validation: Model trained on 2018-2021, validated on Jul-Dec 2022</em>
                        <em>Test Metrics: 91.3% accuracy, 87.2% recall, 78.4% precision</em>
                        <em>Confusion Matrix: 19,200 TN, 1,600 FP, 240 FN, 1,600 TP (out of 22,640 test loans)</em>
                        <em>Comparison: Legacy system had 68% recall ‚Üí 28% improvement (560 more defaults caught)</em>
                    </div>
                </div>
            </div>

            <div class="decision-box">
                <h4>üîç Model Interpretability for Regulatory Compliance</h4>
                <p><strong>Requirement:</strong> Federal Reserve requires "explainable AI" for lending decisions (customers can challenge denials)</p>
                <p><strong>Solution: SHAP (SHapley Additive exPlanations) Values</strong></p>
                <p><strong>How It Works:</strong> For each prediction, SHAP calculates how much each feature contributed to the decision</p>
                <p><strong>Example Denial Explanation:</strong></p>
                <ul>
                    <li>"Your application was declined due to: High debt-to-income ratio (43%, contributed +0.18 to risk score), Recent delinquency (+0.12), Low FICO score (620, +0.09)"</li>
                    <li>Customer can address issues and reapply (vs. black-box rejection)</li>
                </ul>
                <p><strong>Legal Approval:</strong> Compliance team approved SHAP explanations as meeting adverse action notice requirements</p>
            </div>
        </div>

        <div class="content-section">
            <h2>Phase 5: Production Deployment & Monitoring</h2>

            <div class="pipeline-visual">
                <h4>üöÄ Production Architecture</h4>
                <div class="pipeline-step">
                    <strong>Real-Time API</strong><br>
                    Loan application submitted ‚Üí Python Flask API ‚Üí XGBoost model inference (<10ms) ‚Üí Approve/Deny decision
                </div>
                <div class="pipeline-step">
                    <strong>Decision Logging</strong><br>
                    All predictions logged to database ‚Üí Tracks model version, features, prediction, actual outcome (for monitoring)
                </div>
                <div class="pipeline-step">
                    <strong>Human Override</strong><br>
                    Loan officers can override model for edge cases ‚Üí Manual approval/denial with justification logged
                </div>
                <div class="pipeline-step">
                    <strong>A/B Testing Framework</strong><br>
                    10% of applications scored by legacy system + new model ‚Üí Compare default rates over 3 months
                </div>
                <div class="pipeline-step">
                    <strong>Model Monitoring Dashboard</strong><br>
                    Daily metrics: Approval rate, predicted default rate, feature distributions, model drift alerts
                </div>
            </div>

            <div class="workflow-diagram">
                <h4>üìä Monitoring & Model Governance</h4>

                <div class="flow-step">
                    <div class="step-number">1</div>
                    <div>
                        <strong>Performance Degradation Detection</strong><br>
                        <em>Metric: Track actual default rate of approved loans vs. predicted</em>
                        <em>Alert: If actual default rate >10% above predicted for 2 consecutive weeks</em>
                        <em>Root Cause Analysis: Detected spike in March 2023 due to COVID forbearance expirations</em>
                        <em>Action: Retrained model with updated economic indicators</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">2</div>
                    <div>
                        <strong>Data Drift Monitoring</strong><br>
                        <em>Check: Feature distributions in production vs. training data</em>
                        <em>Example: Average FICO score in production dropped from 720 to 695 (shift in applicant pool)</em>
                        <em>Detection: Kolmogorov-Smirnov test flagged significant drift</em>
                        <em>Response: Model still performed well (no retraining needed), but monitored closely</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">3</div>
                    <div>
                        <strong>Quarterly Model Retraining</strong><br>
                        <em>Schedule: Every 3 months, retrain on most recent 2 years of data</em>
                        <em>Validation: New model must outperform current model on holdout set</em>
                        <em>Governance: Model review board approves deployment (Risk, Compliance, IT)</em>
                        <em>Version Control: All model versions archived with full lineage (data, code, config)</em>
                    </div>
                </div>

                <div class="flow-step">
                    <div class="step-number">4</div>
                    <div>
                        <strong>A/B Test Results (3-Month Trial)</strong><br>
                        <em>Group A (Legacy System): 8.5% default rate, 72% approval rate</em>
                        <em>Group B (XGBoost Model): 7.4% default rate, 75% approval rate</em>
                        <em>Result: 13% reduction in defaults + 3% increase in approvals</em>
                        <em>Decision: Rolled out XGBoost to 100% of applications</em>
                    </div>
                </div>
            </div>
        </div>

        <div class="impact-section">
            <h2>Business Impact & Results</h2>
            
            <div class="metrics-grid">
                <div class="metric-card">
                    <div class="metric-number">91.3%</div>
                    <div class="metric-label">Model Accuracy</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">12%</div>
                    <div class="metric-label">Reduction in Default Rate</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">$4.2M</div>
                    <div class="metric-label">Annual Savings from Bad Debt Prevention</div>
                </div>
                <div class="metric-card">
                    <div class="metric-number">50K+</div>
                    <div class="metric-label">Monthly Loan Applications Scored</div>
                </div>
            </div>

            <h3>Key Business Outcomes</h3>
            <ul>
                <li><strong>Default Reduction:</strong> Decreased from 8.5% to 7.4% default rate (13% relative improvement)</li>
                <li><strong>Loss Prevention:</strong> Estimated $4.2M/year savings from prevented bad debt write-offs</li>
                <li><strong>Approval Rate Maintained:</strong> 75% approval rate (vs. 72% legacy) ‚Üí More customers served</li>
                <li><strong>Faster Decisions:</strong> Real-time API (<10ms) vs. 2-day manual review for edge cases</li>
                <li><strong>Regulatory Compliance:</strong> SHAP explanations meet ECOA adverse action notice requirements</li>
                <li><strong>Risk Management:</strong> Identified 560 additional high-risk applicants per month vs. legacy system</li>
            </ul>

            <h3>Key Technical Learnings</h3>
            <ol>
                <li><strong>Feature Engineering > Model Complexity:</strong> Simple engineered features (DTI, utilization ratio) added more value than complex models</li>
                <li><strong>Class Imbalance Critical:</strong> scale_pos_weight improved recall from 68% to 87% (single most impactful parameter)</li>
                <li><strong>Threshold Optimization Essential:</strong> Default 0.5 threshold left $280K/month on table vs. optimized 0.42</li>
                <li><strong>Time-Based Splits Mandatory:</strong> Random CV overly optimistic (93% accuracy); temporal validation realistic (91%)</li>
                <li><strong>Explainability = Trust:</strong> SHAP values convinced skeptical loan officers to adopt model</li>
                <li><strong>Monitor Everything:</strong> Data drift detection prevented silent model degradation</li>
            </ol>

            <h3>Model Selection Insights</h3>
            <p><strong>When to Use XGBoost:</strong> Structured/tabular data, need interpretability, class imbalance, production speed critical</p>
            <p><strong>When NOT to Use:</strong> Small datasets (<1K rows), real-time retraining needed, pure time-series (use LSTM/ARIMA instead)</p>
            <p><strong>XGBoost vs. Random Forest:</strong> XGBoost faster inference (10ms vs. 45ms) and 2% more accurate in our tests</p>
            <p><strong>XGBoost vs. Deep Learning:</strong> Neural nets marginally worse (90.5% vs. 91.3%) and black-box (compliance risk)</p>
        </div>

        <div class="content-section">
            <h2>Tools & Technologies</h2>
            <div class="tech-stack">
                <span class="tech-badge">Python</span>
                <span class="tech-badge">XGBoost</span>
                <span class="tech-badge">Scikit-learn</span>
                <span class="tech-badge">SHAP</span>
                <span class="tech-badge">Pandas</span>
                <span class="tech-badge">Optuna</span>
                <span class="tech-badge">Flask API</span>
                <span class="tech-badge">PostgreSQL</span>
                <span class="tech-badge">Docker</span>
                <span class="tech-badge">AWS EC2</span>
                <span class="tech-badge">Tableau</span>
                <span class="tech-badge">Git/GitHub</span>
            </div>

            <h3>Project Timeline</h3>
            <p><strong>Total Duration:</strong> 5 months (January - May 2023)</p>
            <ul>
                <li>Month 1: Data collection, quality assessment, exploratory analysis</li>
                <li>Month 2: Feature engineering, domain expert collaboration</li>
                <li>Month 3: Model experimentation, XGBoost tuning, validation</li>
                <li>Month 4: Fairness testing, compliance review, API development</li>
                <li>Month 5: A/B testing, monitoring dashboard, production rollout</li>
            </ul>
        </div>

        <a href="index.html" class="back-button">‚Üê Back to Portfolio</a>
    </div>
</body>
</html>
